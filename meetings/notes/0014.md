# SIG-Testing meeting notes from 2022-02-11 @ 1930 UTC

* Moderator: Kadino
* Note Taker: Kadino

## Intermittent Test Failures

Some contributors present today are investigating automated tests which are intermittently failing. While SIG-Testing does not directly own maintaining these tests, nor all stability concerns in Automated Review, we propose SIG-Testing should own the following improvements:

1. A concrete definition of "sufficiently stable for CI" such as "the entire suite encounters an unexpected failure less than 5% of executions" and "an individual test encounters an unexpected failure less than 1% of executions"
2. Propose RFC(s) to take automatic action based on the definition above
3. Propose RFC(s) to evaluate test stability

What is real failure of the product, versus a failure from the test or the test framework?

* Handling of this exists as metrics on failure, but is insufficiently communicated to contributors
  * Tracking of individual failures and failure rates, and a couple of graphs.
  * Basic info is there, but these metrics are not yet adopted by the Linux Foundation.
  * Still difficult to separate a "true" failure of the product, perhaps requires user input? This will be fallible and scale poorly.
* Without easy access to metrics, contributors are left to make assumptions

Important to differentiate an intermittently failing test and an intermittent integration issue. Difficult to tell between intermittent error and a race condition.

Some contributors are casting blame to the tests, where test itself is not flaky. Intermittent failures should be commmunicated more clear than "intermittent test" since most currently point to actual engine issues.

Need data to prove where the intermittent failures are coming from, this often means adding in more logging.

Add a GHI process for a label to track where things came from? SIG-Testing likely shouldn't dictate this. Developers won't reliably follow this.

Typical workflow for intermittent failure is to move to sandbox or remove it. Good to cut tickets tracking when things are sandboxed, as a recommended workflow for SIGs.

Automated report on sandbox: track lifespan for test in sandbox.

## Issues and Planning

Issues with existing test tools, test scripts, or failures in automated review should be cut in the main O3DE Repo, and tagged for sig/testing. Anything related to longer-term plans and RFCs should be cut into the SIG-Testing repo.

Echoing that point: problem statements in issue format help develop solutions. It is easier to design a solution when there are thoughts recorded about what the problems are, and not just a proposed fix.

## General Discussion

No additional discussion.

RFC for [Parallel and batched expansion](https://github.com/o3de/sig-testing/issues/27) was reviewed, the discussion result was to make this specific to MaterialEditor

MaterialEditor tests are currently the only old-style tests which use log monitor, launch-and-validate process, using "windowsgeneric" in LyTT.

GameLauncher will need a clear, useful way that a game level can execute tests, and return an exit code to a framework. Can technically write this today, even without an additional test framework.  Existing ScriptCanvas nodes or Lua can technically work for this, and does not require the full [in-game harness RFC](https://github.com/o3de/sig-testing/issues/20) proposal.

## Action Items

Kadino: draft definitions and propose RFCs for test stability
Kadino: clarify recommended workflow for using the sandbox suite
